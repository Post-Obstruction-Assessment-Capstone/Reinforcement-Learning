{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "824a20e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Makes the display take up more of the screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d2c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import timm \n",
    "from  torch import randn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81002b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b22ccda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.12'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6296c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arch='tf_mobilenetv3_small_075'#'efficientnet_b3a'\n",
    "input_channels = 4\n",
    "num_outputs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615301f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _is_pool_type(l): return re.search(r'Pool[123]d$', l.__class__.__name__)\n",
    "\n",
    "def has_pool_type(m):\n",
    "    \"Return `True` if `m` is a pooling layer or has one in its children\"\n",
    "    if _is_pool_type(m): return True\n",
    "    for l in m.children():\n",
    "        if has_pool_type(l): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253d430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_first_layer(m):\n",
    "    \"Access first layer of a model\"\n",
    "    c,p,n = m,None,None  # child, parent, name\n",
    "    for n in next(m.named_parameters())[0].split('.')[:-1]:\n",
    "        p,c=c,getattr(c,n)\n",
    "    return c,p,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ccd4c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _update_first_layer(model, n_in, pretrained):\n",
    "    \"Change first layer based on number of input channels\"\n",
    "    if n_in == 3: return\n",
    "    first_layer, parent, name = _get_first_layer(model)\n",
    "    assert isinstance(first_layer, nn.Conv2d), f'Change of input channels only supported with Conv2d, found {first_layer.__class__.__name__}'\n",
    "    assert getattr(first_layer, 'in_channels') == 3, f'Unexpected number of input channels, found {getattr(first_layer, \"in_channels\")} while expecting 3'\n",
    "    params = {attr:getattr(first_layer, attr) for attr in 'out_channels kernel_size stride padding dilation groups padding_mode'.split()}\n",
    "    params['bias'] = getattr(first_layer, 'bias') is not None\n",
    "    params['in_channels'] = n_in\n",
    "    new_layer = nn.Conv2d(**params)\n",
    "    if pretrained:\n",
    "        _load_pretrained_weights(new_layer, first_layer)\n",
    "    setattr(parent, name, new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf3ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _load_pretrained_weights(new_layer, previous_layer):\n",
    "    \"Load pretrained weights based on number of input channels\"\n",
    "    n_in = getattr(new_layer, 'in_channels')\n",
    "    if n_in==1:\n",
    "        # we take the sum\n",
    "        new_layer.weight.data = previous_layer.weight.data.sum(dim=1, keepdim=True)\n",
    "    elif n_in==2:\n",
    "        # we take first 2 channels + 50%\n",
    "        new_layer.weight.data = previous_layer.weight.data[:,:2] * 1.5\n",
    "    else:\n",
    "        # keep 3 channels weights and set others to null\n",
    "        new_layer.weight.data[:,:3] = previous_layer.weight.data\n",
    "        new_layer.weight.data[:,3:].zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c563a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2289dc61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export\n",
    "def freezeCNNLayers(model):\n",
    "    \"This leaves the head with gradients but sets the layers before the AdaptiveAvgPool2d to not update\"\n",
    "    # there is probably a more elequent way to do this\n",
    "    for child in model.children():\n",
    "        try: #'AdaptiveAvgPool2d' not subscriptable if pooling changes this may not work\n",
    "            _ = child[0]\n",
    "            for param in child.parameters(): param.requires_grad = False\n",
    "        except: pass #    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9cb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n",
    "    \"Creates a body from any model in the `timm` library.\"\n",
    "    model = timm.create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): return cut(model)\n",
    "    else: raise NamedError(\"cut must be either integer or function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26e1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "body = create_timm_body(arch, pretrained=True, cut=None, n_in=input_channels)\n",
    "\n",
    "\n",
    "x = randn(1, input_channels, 224, 224);  #expected image size (mobileNet requires 224x224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5613b6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4a8910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 432, 7, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8c4e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ModelMaker(arch='tf_mobilenetv3_small_075', input_channels = 4, num_outputs = 7, dropout=0.2):\n",
    "    \"Creates a custom pretrained CNN\"\n",
    "    body = create_timm_body(arch=arch, pretrained=True, cut=None, n_in=input_channels)\n",
    "    x = randn(1, input_channels, 224, 224);  #expected image size (mobileNet requires 224x224)    \n",
    "    num_in_features=body(x).shape[1]\n",
    "    \n",
    "    model=nn.Sequential(body,\n",
    "        nn.AdaptiveAvgPool2d(1),       \n",
    "        nn.Flatten(),\n",
    "        nn.BatchNorm1d(num_in_features), # nn.LayerNorm may be better see: lesson 31 in Actor/Critic Phil Tabor course\n",
    "        nn.Linear(in_features=num_in_features,out_features=512, bias=False), \n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(512),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(in_features=512, out_features=num_outputs, bias=False)\n",
    "    )\n",
    "    #freezeCNNLayers(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cf2d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ModelMaker(arch='tf_mobilenetv3_small_075', input_channels = 4, num_outputs = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfb412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a756ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for child in model.children():\n",
    "        \n",
    " #   for param in child.parameters(): \n",
    "  #      print(param.requires_grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343bb55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0227bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "freezeCNNLayers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2769132d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa8b93f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 224, 224])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fceaea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1573, -0.1663,  0.2694, -0.1124, -0.3671,  0.1126, -0.1601]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test to ensure model produces results\n",
    "model.eval()\n",
    "actions=model(x)\n",
    "model.train()\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ef182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fe16d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2824, -0.1124,  0.2885, -0.1344, -0.4955,  0.0785, -0.1877]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = randn(1, input_channels, 480, 480)\n",
    "model.eval()\n",
    "actions=model(x)\n",
    "model.train()\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fd095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1a335d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted NeuralNetwork.ipynb to nbdev/nb_NeuralNetwork.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py NeuralNetwork.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed95e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Sunday February 20, 2022 at 09:22\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "end=dt.datetime.now()\n",
    "print(f'Finished: {end.strftime(\"%A %B %d, %Y\")} at {end.strftime(\"%H:%M\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
